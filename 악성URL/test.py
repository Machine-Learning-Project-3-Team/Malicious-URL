import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv("C:/Users/user/Desktop/25-1/ê¸°ê³„í•™ìŠµ/ì–¸ë”ìƒ˜í”Œë§/malicious_only.csv")
urls = df['url'].dropna().tolist()  # ê²°ì¸¡ì¹˜ ì œê±°

# ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ìœ„ì¥ëœ User-Agent
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
}

# ìœ„í—˜ í™•ì¥ì ë¦¬ìŠ¤íŠ¸
dangerous_ext = ('.zip', '.exe', '.apk', '.rar', '.bat', '.js')

for idx, url in enumerate(urls):
    print(f"\nğŸ”— [{idx + 1}] {url}")

    # ìë™ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ URL ì‚¬ì „ í•„í„°ë§
    if url.lower().endswith(dangerous_ext):
        print("âš ï¸ ë‹¤ìš´ë¡œë“œ ìœ„í—˜ í™•ì¥ì URL â†’ ë¶„ì„ ì œì™¸ë¨.")
        continue

    try:
        # ìš”ì²­: ë¦¬ë‹¤ì´ë ‰íŠ¸ ë° ì‹¤í–‰ ë°©ì§€
        response = requests.get(url, headers=headers, timeout=10, allow_redirects=False)
        html = response.text

        # HTML íŒŒì‹±
        soup = BeautifulSoup(html, "html.parser")

        print("\nğŸ“„ HTML êµ¬ì¡°:")
        print(soup.prettify()[:2000])  # ìµœëŒ€ 2000ì ì¶œë ¥

        print("\nğŸ“œ JavaScript ì½”ë“œ:")
        scripts = soup.find_all("script")
        for i, script in enumerate(scripts):
            if script.string:
                print(f"\n[Script {i + 1}]\n{script.string[:1000]}")  # ìµœëŒ€ 1000ì ì¶œë ¥
            else:
                print(f"\n[Script {i + 1}] ì™¸ë¶€ JS ë˜ëŠ” ë¹„ì–´ ìˆìŒ")

    except requests.exceptions.RequestException as e:
        print(f"âŒ ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}")
    except Exception as e:
        print(f"âŒ ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ìš”ì²­ ê°„ ì‹œê°„ ê°„ê²© ì„¤ì • (Rate Limit ë°©ì§€)
    time.sleep(1)

    try:
        input("\nâ Enterë¥¼ ëˆ„ë¥´ë©´ ë‹¤ìŒ URLë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...")
    except KeyboardInterrupt:
        print("\nâ›” ì‚¬ìš©ì ì¤‘ë‹¨ìœ¼ë¡œ ë¶„ì„ ì¢…ë£Œ")
        break
